{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing the necessary libraries\nimport os\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define directories for negative (no crack) and positive (crack) images\ndataset_dir = '/kaggle/input/concrete-crack-images-for-classification'\n\n# Initialize ImageDataGenerator with rescaling and augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,  # Normalize pixel values between 0 and 1\n    rotation_range=15,  # Random rotation between 0-15 degrees\n    width_shift_range=0.1,  # Randomly shift images horizontally (10%)\n    height_shift_range=0.1,  # Randomly shift images vertically (10%)\n    horizontal_flip=True,  # Flip images horizontally\n    validation_split=0.2  # Reserve 20% of data for validation\n)\n\n# Train generator: loads batches of images from the dataset directory\ntrain_generator = train_datagen.flow_from_directory(\n    dataset_dir,  # Dataset directory\n    target_size=(227, 227),  # Resize images to 227x227\n    batch_size=32,  # Number of images in each batch\n    class_mode='categorical',  # Binary classification (crack vs no crack)\n    subset='training'  # 80% for training\n)\n\n# Validation generator: loads batches for validation\nvalidation_generator = train_datagen.flow_from_directory(\n    dataset_dir,  # Same dataset directory\n    target_size=(227, 227),  # Same target size for validation\n    batch_size=32,  # Batch size\n    class_mode='categorical',  # Binary classification\n    subset='validation'  # 20% for validation\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the CNN model\nmodel = Sequential()\n\n# 1st Convolutional Layer (Conv2D + MaxPooling)\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(227, 227, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# 2nd Convolutional Layer (Conv2D + MaxPooling)\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Flatten the layers (convert 2D feature maps to 1D feature vectors)\nmodel.add(Flatten())\n\n# Fully Connected Layer (Dense)\nmodel.add(Dense(64, activation='relu'))\n\n# Output Layer (Dense with softmax activation for binary classification)\nmodel.add(Dense(2, activation='softmax'))\n\n# Compile the model with Adam optimizer and categorical crossentropy loss\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Print the model summary to verify the architecture\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model with the train and validation data generators\nhistory = model.fit(\n    train_generator,  # Training data loaded in batches\n    epochs=10,  # Number of training epochs\n    validation_data=validation_generator  # Validation data loaded in batches\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the validation set\nval_loss, val_accuracy = model.evaluate(validation_generator)\nprint(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}